{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "TD4Kuz62SAiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WCuttuLwNovY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import threading\n",
        "from urllib.parse import urlparse\n",
        "import torch\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import requests\n",
        "import json\n",
        "\n",
        "app = Flask(__name__)  # Initialize flask app , Using flask as backend\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading BERT model  and tokenizer\n",
        "model_path = \"/content/bert_model2.pth\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")                        # Using pretrained bert-base-uncased model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "tDK42f-CtrNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract specific data from url for training\n",
        "\n",
        "# Bert model is trained on text\n",
        "\n",
        "def extract_url_components(url):\n",
        "    parsed = urlparse(url)\n",
        "    hostname = parsed.hostname\n",
        "    ip_pattern = r\"^\\d{1,3}(\\.\\d{1,3}){3}$\"\n",
        "    is_ip = bool(re.match(ip_pattern, hostname)) if hostname else False\n",
        "    domain = hostname if not is_ip else hostname\n",
        "    subdomain = \"\" if is_ip or not hostname else '.'.join(hostname.split('.')[:-2]) if hostname.count('.') > 1 else ''\n",
        "    path = parsed.path\n",
        "    file_ext = os.path.splitext(parsed.path)[1] if '.' in os.path.basename(parsed.path) else ''\n",
        "    query_params = parsed.query\n",
        "    input_text = f\"Domain: {domain} Subdomain: {subdomain} Path: {path} FileExt: {file_ext} Query: {query_params} IP: {is_ip}\"\n",
        "    return input_text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5JmA5EJWtpTP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "from flask import Flask, request, jsonify\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Endpoint for testing\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.json[\"url\"]\n",
        "    input_text = extract_url_components(data)\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return jsonify({\"malicious\": bool(prediction)})\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "def run_flask():\n",
        "    app.run(debug=True, host=\"127.0.0.1\", port=5000, use_reloader=False)\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "id": "MiNvf4_Ety9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63087da2-5d6d-484f-850a-cd9dca3fcebe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "log = logging.getLogger('werkzeug')\n",
        "log.setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "# List of Testing URLs with expected values\n",
        "with open(\"/content/data.txt\", \"r\") as f:\n",
        "    url_data = json.load(f)\n",
        "\n",
        "\n",
        "# Sending a Post request to the endpoint to check if url is malicious\n",
        "api_url = \"http://127.0.0.1:5000/predict\"\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "# Counters for accuracy calculation\n",
        "total = len(url_data)\n",
        "correct = 0\n",
        "\n",
        "for entry in url_data:\n",
        "    data = {\"url\": entry[\"url\"]}\n",
        "    response = requests.post(api_url, json=data, headers=headers)      # Getting response from backend\n",
        "    if response.status_code == 200:\n",
        "        result = response.json().get(\"malicious\")\n",
        "        if result:\n",
        "          predicted = \"phishing\"\n",
        "        else:\n",
        "          predicted =  \"legit\"\n",
        "\n",
        "        #print(f\"URL: {entry['url']}\")\n",
        "        #print(f\"Expected: {entry['expected']}, Predicted: {predicted}\")\n",
        "        #print(\"--\" * 20)\n",
        "\n",
        "        if predicted == entry[\"expected\"]:  # checking if Model gave correct response and increaing counter\n",
        "            correct += 1\n",
        "    else:\n",
        "        print(f\"Failed to get response for {entry['url']}\")\n",
        "\n",
        "# CAccuracy calculation\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Accuracy: {accuracy}%\")\n"
      ],
      "metadata": {
        "id": "KpD95trHRxHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2761628-2cb8-4f5a-9bd4-2e99d4a40e9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.2439024390244%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1S5Y2D0su-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}